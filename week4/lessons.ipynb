{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a7c123f",
   "metadata": {},
   "source": [
    "# Lesson 4.1\n",
    "# Searching (A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfc0a54",
   "metadata": {},
   "source": [
    "## 1. Reflex agents (the simplest kind)\n",
    "\n",
    "A reflex agent works like a rulebook:\n",
    "\n",
    "It looks at the current state\n",
    "\n",
    "Immediately chooses an action\n",
    "\n",
    "No thinking about the future\n",
    "\n",
    "Example:\n",
    "‚ÄúIf the square is dirty ‚Üí suck.‚Äù\n",
    "‚ÄúIf the square is clean ‚Üí move right.‚Äù\n",
    "\n",
    "There is no planning, no memory of what might happen next. Just state ‚Üí action.\n",
    "\n",
    "\n",
    "## 2. Goal-based agents (more intelligent)\n",
    "\n",
    "A goal-based agent is smarter because:\n",
    "\n",
    "It has a goal (what it wants to achieve)\n",
    "\n",
    "It thinks ahead\n",
    "\n",
    "It considers future actions and outcomes\n",
    "\n",
    "Instead of asking ‚ÄúWhat do I do now?‚Äù, it asks:\n",
    "‚ÄúWhat should I do to reach my goal?‚Äù\n",
    "\n",
    "This requires reasoning and planning.\n",
    "\n",
    "## 3. Problem-solving agents (a type of goal-based agent)\n",
    "\n",
    "A problem-solving agent is a specific kind of goal-based agent that works in three main steps:\n",
    "\n",
    "Formulate the problem\n",
    "\n",
    "Define:\n",
    "\n",
    "Initial state (where I am now)\n",
    "\n",
    "Goal state (what I want)\n",
    "\n",
    "Possible actions\n",
    "\n",
    "Costs (optional)\n",
    "\n",
    "Search for a solution\n",
    "\n",
    "It searches for a sequence of actions that leads from the initial state to the goal\n",
    "\n",
    "Uses algorithms like BFS, DFS, A*, etc.\n",
    "\n",
    "Execute the plan\n",
    "\n",
    "Once a plan is found, it executes actions one by one\n",
    "\n",
    "Important point:\n",
    "üëâ Planning happens first, execution happens after."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24f83a7",
   "metadata": {},
   "source": [
    "### Simple vacuum-cleaner example\n",
    "\n",
    "Initial state: some rooms are dirty\n",
    "\n",
    "Goal: all rooms are clean\n",
    "\n",
    "Agent:\n",
    "\n",
    "Plans a path to visit dirty rooms\n",
    "\n",
    "Decides when to move and when to clean\n",
    "\n",
    "Executes the plan step by step\n",
    "\n",
    "This is problem solving, not reflex behavior.\n",
    "\n",
    "### Key takeaway\n",
    "\n",
    "Reflex agent: reacts\n",
    "\n",
    "Goal-based agent: reasons about goals\n",
    "\n",
    "Problem-solving agent: plans first, then acts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b591f",
   "metadata": {},
   "source": [
    "#### Big picture: what is ‚Äúsearching‚Äù here?\n",
    "\n",
    "We are modeling problem-solving as search.\n",
    "\n",
    "The world is a graph (cities + roads)\n",
    "\n",
    "The agent starts somewhere (Arad)\n",
    "\n",
    "The goal is to reach Bucharest\n",
    "\n",
    "The agent must search for a sequence of actions (moves) to reach the goal\n",
    "\n",
    "\n",
    "#### 1. Goal\n",
    "\n",
    "‚ÄúAn agent is in Arad, Romania. The goal is to drive to Bucharest.‚Äù\n",
    "\n",
    "A goal defines what success looks like.\n",
    "\n",
    "Without a goal, the agent has no direction\n",
    "\n",
    "The goal limits what the agent needs to consider\n",
    "\n",
    "Here:\n",
    "\n",
    "Goal = being in Bucharest\n",
    "\n",
    "\n",
    "#### 2. Initial State\n",
    "\n",
    "Initial State: In(Arad)\n",
    "\n",
    "The initial state is where the agent starts.\n",
    "\n",
    "State is a description of the world relevant to the problem\n",
    "\n",
    "In this problem, a state is simply:\n",
    "\n",
    "In(city_name)\n",
    "\n",
    "Example:\n",
    "\n",
    "Initial state = In(Arad)\n",
    "\n",
    "\n",
    "#### 3. Actions\n",
    "\n",
    "ACTIONS(s) returns the set of actions available in state s\n",
    "\n",
    "An action is something the agent can do from a given state.\n",
    "\n",
    "From In(Arad), the agent can:\n",
    "\n",
    "Go(Sibiu)\n",
    "\n",
    "Go(Timisoara)\n",
    "\n",
    "Go(Zerind)\n",
    "\n",
    "So:\n",
    "\n",
    "ACTIONS(In(Arad)) = { Go(Sibiu), Go(Timisoara), Go(Zerind) }\n",
    "\n",
    "\n",
    "Important:\n",
    "\n",
    "Actions depend on the current state\n",
    "\n",
    "You cannot ‚ÄúGo(Bucharest)‚Äù directly unless there is a road\n",
    "\n",
    "\n",
    "#### 4. Transition Model (RESULT function)\n",
    "\n",
    "RESULT(s, a) returns the state that results from doing action a in state s\n",
    "\n",
    "This defines what happens when you take an action.\n",
    "\n",
    "Example:\n",
    "\n",
    "RESULT(In(Arad), Go(Zerind)) = In(Zerind)\n",
    "\n",
    "\n",
    "This is also called a successor:\n",
    "\n",
    "A successor is any state reachable in one action\n",
    "\n",
    "\n",
    "#### 5. Goal State and Goal Test\n",
    "\n",
    "A goal is a set of world states\n",
    "\n",
    "A goal state is any state where the goal is satisfied.\n",
    "\n",
    "Here:\n",
    "\n",
    "Goal states = { In(Bucharest) }\n",
    "\n",
    "\n",
    "The goal test checks:\n",
    "\n",
    "Is current_state == In(Bucharest)?\n",
    "\n",
    "\n",
    "If yes ‚Üí stop\n",
    "\n",
    "If no ‚Üí continue searching\n",
    "\n",
    "\n",
    "#### 6. Path Cost Function\n",
    "\n",
    "Assigns a numeric cost to each path\n",
    "\n",
    "This tells the agent which solution is better.\n",
    "\n",
    "In the Romania problem:\n",
    "\n",
    "Cost = total distance (km)\n",
    "\n",
    "Example:\n",
    "\n",
    "Arad ‚Üí Sibiu ‚Üí Fagaras ‚Üí Bucharest\n",
    "\n",
    "Cost = 140 + 99 + 211\n",
    "\n",
    "The agent prefers:\n",
    "\n",
    "Lower total cost\n",
    "\n",
    "Not just any path, but the best one\n",
    "\n",
    "#### 7. Problem Formulation (very important)\n",
    "\n",
    "Problem formulation means deciding what to include:\n",
    "\n",
    "States: In(city)\n",
    "\n",
    "Initial state: In(Arad)\n",
    "\n",
    "Actions: Go(city)\n",
    "\n",
    "Transition model: RESULT(s, a)\n",
    "\n",
    "Goal test: In(Bucharest)?\n",
    "\n",
    "Path cost: sum of distances\n",
    "\n",
    "Once this is defined, search algorithms (BFS, DFS, UCS, A*) can be applied.\n",
    "\n",
    "\n",
    "## One-sentence exam summary\n",
    "\n",
    "A problem-solving agent formulates a problem by defining the initial state, actions, transition model, goal test, and path cost, then searches for a sequence of actions that leads from the initial state to a goal state with minimum cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7fa329",
   "metadata": {},
   "source": [
    "# Lesson 4.2\n",
    "# Searching (B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd216a64",
   "metadata": {},
   "source": [
    "## 1. State space graph\n",
    "\n",
    "A state space graph is the true mathematical model of the problem.\n",
    "\n",
    "Nodes = states (abstract descriptions of the world)\n",
    "\n",
    "Edges (arcs) = actions / transitions between states\n",
    "\n",
    "Goal nodes = states that satisfy the goal test\n",
    "\n",
    "### Key rule (very important):\n",
    "\n",
    "Each state appears only once in the state space graph.\n",
    "\n",
    "Example interpretations:\n",
    "\n",
    "Romania map: each city is a state\n",
    "\n",
    "Vacuum world: each configuration of agent location + dirt is a state\n",
    "\n",
    "This graph exists conceptually, even if we never build it fully.\n",
    "\n",
    "### 2. Why state space graphs matter\n",
    "\n",
    "They answer:\n",
    "\n",
    "What states are possible?\n",
    "\n",
    "How states connect\n",
    "\n",
    "Whether cycles exist\n",
    "\n",
    "Whether a solution exists at all\n",
    "\n",
    "But:\n",
    "üëâ We almost never search directly on the full state space graph\n",
    "Because it can be huge or infinite.\n",
    "\n",
    "\n",
    "## 3. Search tree\n",
    "\n",
    "A search tree is what the algorithm actually builds while searching.\n",
    "\n",
    "Critical difference:\n",
    "\n",
    "State space graph: states are unique\n",
    "\n",
    "Search tree: the same state can appear many times\n",
    "\n",
    "Why?\n",
    "\n",
    "Because the same state can be reached via different paths\n",
    "\n",
    "Example:\n",
    "\n",
    "Arad ‚Üí Sibiu ‚Üí Arad\n",
    "\n",
    "Arad appears again, but via a different path\n",
    "\n",
    "So in the search tree:\n",
    "\n",
    "Nodes = paths, not just states\n",
    "\n",
    "This sentence from the slide is gold:\n",
    "\n",
    "#### Each node in the search tree is an entire path in the state space graph\n",
    "\n",
    "\n",
    "## 4. State space graph vs search tree (core comparison)\n",
    "\n",
    "| Aspect           | State Space Graph  | Search Tree           |\n",
    "| ---------------- | ------------------ | --------------------- |\n",
    "| Nodes            | States             | Paths                 |\n",
    "| Duplicate states | No                 | Yes                   |\n",
    "| Cycles           | Shown once         | Cause infinite growth |\n",
    "| Size             | Finite (usually)   | Can be infinite       |\n",
    "| Used for         | Problem definition | Actual search         |\n",
    "\n",
    "\n",
    "## 5. Why search trees can be infinite\n",
    "\n",
    "Look at the 4-state example with cycles (S, a, b, G):\n",
    "\n",
    "a ‚Üî b form a loop\n",
    "\n",
    "You can go:\n",
    "S ‚Üí a ‚Üí b ‚Üí a ‚Üí b ‚Üí a ‚Üí ...\n",
    "\n",
    "So the state space graph is small (4 states), but:\n",
    "\n",
    "The search tree is infinite\n",
    "\n",
    "That infinity symbol on the slide is not decoration.\n",
    "It means:\n",
    "\n",
    "Without cycle checking, search may never terminate\n",
    "\n",
    "This is why graph search (visited set) matters\n",
    "\n",
    "\n",
    "## 6. Repeated structure in search trees\n",
    "\n",
    "The slide saying:\n",
    "\n",
    "‚ÄúImportant: lots of repeated structure in the search tree‚Äù\n",
    "\n",
    "Means:\n",
    "\n",
    "The same subproblems are solved again and again\n",
    "\n",
    "Waste of time and memory\n",
    "\n",
    "Motivates:\n",
    "\n",
    "Graph search\n",
    "\n",
    "Closed lists\n",
    "\n",
    "Heuristics\n",
    "\n",
    "\n",
    "## 7. Search tree example (Romania)\n",
    "\n",
    "Root: In(Arad)\n",
    "\n",
    "First expansion: {Sibiu, Timisoara, Zerind}\n",
    "\n",
    "Expand Sibiu ‚Üí generates Arad again, plus others\n",
    "\n",
    "Important visual cues:\n",
    "\n",
    "Shaded nodes: already expanded\n",
    "\n",
    "Bold outline: generated but not expanded\n",
    "\n",
    "Dashed: not generated yet\n",
    "\n",
    "This shows incremental construction:\n",
    "\n",
    "We only build what we need, when we need it.\n",
    "\n",
    "\n",
    "## 8. Search performance criteria (very exam-relevant)\n",
    "\n",
    "Before choosing a search algorithm, we judge it by four criteria:\n",
    "\n",
    "### 1. Completeness\n",
    "\n",
    "Will it find a solution if one exists?\n",
    "\n",
    "Example:\n",
    "\n",
    "BFS: Yes (finite branching)\n",
    "\n",
    "DFS: Not always (can get stuck in loops)\n",
    "\n",
    "### 2. Optimality\n",
    "\n",
    "Will it find the best solution?\n",
    "\n",
    "Example:\n",
    "\n",
    "BFS: Optimal if all step costs are equal\n",
    "\n",
    "UCS / A*: Yes (under conditions)\n",
    "\n",
    "### 3. Time complexity\n",
    "\n",
    "How many nodes does it generate?\n",
    "\n",
    "Usually expressed as:\n",
    "\n",
    "branching factor b\n",
    "\n",
    "depth d\n",
    "\n",
    "e.g. O(b^d)\n",
    "\n",
    "\n",
    "### 4. Space complexity\n",
    "\n",
    "How much memory does it use?\n",
    "\n",
    "Key idea:\n",
    "\n",
    "BFS uses a lot of memory\n",
    "\n",
    "DFS uses much less memory\n",
    "\n",
    "A* can be very memory-heavy\n",
    "\n",
    "### One-paragraph exam-ready summary\n",
    "\n",
    "A state space graph is a mathematical representation of a problem in which nodes correspond to unique world states and edges correspond to actions. A search tree, constructed during search, represents paths through the state space and may contain repeated states due to different paths and cycles. Because search trees can grow infinitely even when the state space graph is finite, search algorithms must be evaluated using completeness, optimality, time complexity, and space complexity.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
