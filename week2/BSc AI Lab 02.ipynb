{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Artificial Intelligence (BSc)\n",
    "## Week 2 — What is AI? What is an Agent? (AIMA Ch. 2)\n",
    "\n",
    "Name:\n",
    "\n",
    "Date of last update:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Today’s goals\n",
    "By the end of this notebook you should be able to:\n",
    "- Explain what an **agent** is (in AI terms).\n",
    "- Describe an **environment** and its key properties.\n",
    "- Define **rationality** using performance measures and constraints.\n",
    "- Implement and explain a very simple **reflex agent**.\n",
    "- Practise **explainability**: explain *why* your agent acts the way it does.\n",
    "\n",
    "### How to use this notebook\n",
    "- Read the markdown cells first.\n",
    "- Run code cells in order.\n",
    "- Fill in the **TODO** sections.\n",
    "- Answer the reflection questions in **your own words**.\n",
    "\n",
    "### Reading\n",
    "- Russell & Norvig (AIMA), Chapter 2: Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "Run this cell first. If something errors, ask for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "print('Setup complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Concepts: Agent, Environment, Percepts, Actions\n",
    "\n",
    "In AIMA, an **agent** is anything that:\n",
    "- **perceives** its environment (gets percepts)\n",
    "- **acts** in the environment (takes actions)\n",
    "\n",
    "A simple picture:\n",
    "\n",
    "**Environment → Percepts → Agent → Actions → Environment**\n",
    "\n",
    "### Quick check (write your answers)\n",
    "**Q1:** Is a calculator an agent? Why or why not?\n",
    "\n",
    "**Q2:** Is a thermostat an agent? Why or why not?\n",
    "\n",
    "Write answers below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answers\n",
    "- Q1:\n",
    "- Q2:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A Tiny Environment: 2×2 Vacuum World\n",
    "\n",
    "We will use a very small **grid environment**:\n",
    "- The agent is on one square.\n",
    "- Each square is either **dirty** or **clean**.\n",
    "- The agent can:\n",
    "  - move up/down/left/right\n",
    "  - clean (\"SUCK\")\n",
    "\n",
    "### Why this environment?\n",
    "It is small enough to understand *every step* and still illustrates real AI ideas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment settings\n",
    "ROWS = 2\n",
    "COLS = 2\n",
    "\n",
    "ACTIONS = ['UP', 'DOWN', 'LEFT', 'RIGHT', 'SUCK']\n",
    "\n",
    "# We represent the world as a dictionary:\n",
    "# world[(r, c)] = True means DIRTY\n",
    "# world[(r, c)] = False means CLEAN\n",
    "\n",
    "def make_random_world(rows: int, cols: int, dirt_prob: float = 0.7) -> Dict[Tuple[int,int], bool]:\n",
    "    world = {}\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            world[(r, c)] = (random.random() < dirt_prob)\n",
    "    return world\n",
    "\n",
    "def print_world(world: Dict[Tuple[int,int], bool], agent_pos: Tuple[int,int], rows: int, cols: int) -> None:\n",
    "    # Simple text display\n",
    "    for r in range(rows):\n",
    "        row_cells = []\n",
    "        for c in range(cols):\n",
    "            is_dirty = world[(r, c)]\n",
    "            if (r, c) == agent_pos:\n",
    "                cell = 'A'  # agent\n",
    "            else:\n",
    "                cell = '.'\n",
    "            cell += 'D' if is_dirty else 'C'\n",
    "            row_cells.append(cell)\n",
    "        print(' '.join(row_cells))\n",
    "    print()\n",
    "\n",
    "world = make_random_world(ROWS, COLS, dirt_prob=0.7)\n",
    "agent_pos = (0, 0)\n",
    "\n",
    "print('Initial world:')\n",
    "print_world(world, agent_pos, ROWS, COLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Separating Environment from Agent\n",
    "\n",
    "For explainability, we will separate:\n",
    "- **Sense** (environment → percept)\n",
    "- **Agent** (percept → action)\n",
    "- **Act** (environment + action → new environment)\n",
    "\n",
    "This separation helps you explain:\n",
    "- what the agent knows\n",
    "- what the agent decides\n",
    "- how the environment changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sense(world: Dict[Tuple[int,int], bool], agent_pos: Tuple[int,int]) -> Dict[str, object]:\n",
    "    \"\"\"Return the percept. Here: location and whether current square is dirty.\"\"\"\n",
    "    r, c = agent_pos\n",
    "    percept = {\n",
    "        'pos': agent_pos,\n",
    "        'is_dirty_here': world[(r, c)]\n",
    "    }\n",
    "    return percept\n",
    "\n",
    "def act(world: Dict[Tuple[int,int], bool], agent_pos: Tuple[int,int], action: str, rows: int, cols: int) -> Tuple[Dict[Tuple[int,int], bool], Tuple[int,int]]:\n",
    "    \"\"\"Apply the action to the environment. Returns (new_world, new_agent_pos).\"\"\"\n",
    "    r, c = agent_pos\n",
    "    new_world = dict(world)  # copy\n",
    "    new_pos = agent_pos\n",
    "\n",
    "    if action == 'SUCK':\n",
    "        # Clean the current square\n",
    "        new_world[(r, c)] = False\n",
    "        return new_world, new_pos\n",
    "\n",
    "    if action == 'UP':\n",
    "        if r > 0:\n",
    "            new_pos = (r - 1, c)\n",
    "    elif action == 'DOWN':\n",
    "        if r < rows - 1:\n",
    "            new_pos = (r + 1, c)\n",
    "    elif action == 'LEFT':\n",
    "        if c > 0:\n",
    "            new_pos = (r, c - 1)\n",
    "    elif action == 'RIGHT':\n",
    "        if c < cols - 1:\n",
    "            new_pos = (r, c + 1)\n",
    "\n",
    "    return new_world, new_pos\n",
    "\n",
    "percept = sense(world, agent_pos)\n",
    "print('Example percept:', percept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. A Simple Reflex Agent\n",
    "\n",
    "A reflex agent uses **if–else rules**.\n",
    "\n",
    "### Reflex rule (very simple)\n",
    "- If current square is dirty → SUCK\n",
    "- Otherwise → move randomly\n",
    "\n",
    "This is not “smart”, but it is a valid agent.\n",
    "\n",
    "### TODO\n",
    "Read the function and make sure you can explain it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflex_agent(percept: Dict[str, object]) -> str:\n",
    "    if percept['is_dirty_here']:\n",
    "        return 'SUCK'\n",
    "    else:\n",
    "        return random.choice(['UP', 'DOWN', 'LEFT', 'RIGHT'])\n",
    "\n",
    "# Test the agent decision once\n",
    "test_percept = {'pos': (0,0), 'is_dirty_here': True}\n",
    "print('If dirty ->', reflex_agent(test_percept))\n",
    "test_percept = {'pos': (0,0), 'is_dirty_here': False}\n",
    "print('If clean ->', reflex_agent(test_percept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Running a Simulation\n",
    "\n",
    "We will run the agent for a number of steps.\n",
    "\n",
    "### Performance measure\n",
    "We need a way to say if the agent is doing well.\n",
    "\n",
    "For now:\n",
    "- **+1** point for each clean square at each time step\n",
    "\n",
    "This means the agent is rewarded for keeping the world clean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(world: Dict[Tuple[int,int], bool], rows: int, cols: int) -> int:\n",
    "    # Count clean squares\n",
    "    clean = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if world[(r, c)] == False:\n",
    "                clean += 1\n",
    "    return clean\n",
    "\n",
    "def run_simulation(agent_fn, steps: int = 10, rows: int = 2, cols: int = 2, dirt_prob: float = 0.7, show: bool = True):\n",
    "    world = make_random_world(rows, cols, dirt_prob)\n",
    "    agent_pos = (0, 0)\n",
    "    total_score = 0\n",
    "\n",
    "    if show:\n",
    "        print('Starting simulation...')\n",
    "        print_world(world, agent_pos, rows, cols)\n",
    "\n",
    "    for t in range(steps):\n",
    "        percept = sense(world, agent_pos)\n",
    "        action = agent_fn(percept)\n",
    "        world, agent_pos = act(world, agent_pos, action, rows, cols)\n",
    "\n",
    "        score_t = performance(world, rows, cols)\n",
    "        total_score += score_t\n",
    "\n",
    "        if show:\n",
    "            print(f'Time {t}: action={action}, score_this_step={score_t}')\n",
    "            print_world(world, agent_pos, rows, cols)\n",
    "\n",
    "    return total_score\n",
    "\n",
    "score = run_simulation(reflex_agent, steps=8, rows=ROWS, cols=COLS, dirt_prob=0.7, show=True)\n",
    "print('Total score:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Explainability Task (Important)\n",
    "\n",
    "Answer in your own words:\n",
    "\n",
    "1. What information does the agent use to decide?\n",
    "2. Why does the agent sometimes move \"badly\"?\n",
    "3. What is the agent trying to maximise in this environment?\n",
    "\n",
    "Write answers below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answers\n",
    "- Q1:\n",
    "- Q2:\n",
    "- Q3:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Rationality Depends on the Performance Measure\n",
    "\n",
    "Let’s change what we mean by “good”.\n",
    "\n",
    "### New performance measure\n",
    "- Clean squares are good\n",
    "- BUT moving costs energy\n",
    "\n",
    "We will implement:\n",
    "- +1 for each clean square per step\n",
    "- -1 for every move action\n",
    "\n",
    "### TODO\n",
    "Complete the function `performance_with_energy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_with_energy(world: Dict[Tuple[int,int], bool], rows: int, cols: int, last_action: str) -> int:\n",
    "    # TODO: start from clean squares score\n",
    "    clean_score = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if world[(r, c)] == False:\n",
    "                clean_score += 1\n",
    "\n",
    "    # TODO: subtract 1 for move actions (UP/DOWN/LEFT/RIGHT)\n",
    "    move_penalty = 0\n",
    "    if last_action in ['UP', 'DOWN', 'LEFT', 'RIGHT']:\n",
    "        move_penalty = 1\n",
    "\n",
    "    return clean_score - move_penalty\n",
    "\n",
    "def run_simulation_energy(agent_fn, steps: int = 10, rows: int = 2, cols: int = 2, dirt_prob: float = 0.7, show: bool = True):\n",
    "    world = make_random_world(rows, cols, dirt_prob)\n",
    "    agent_pos = (0, 0)\n",
    "    total_score = 0\n",
    "\n",
    "    if show:\n",
    "        print('Starting simulation (energy cost)...')\n",
    "        print_world(world, agent_pos, rows, cols)\n",
    "\n",
    "    for t in range(steps):\n",
    "        percept = sense(world, agent_pos)\n",
    "        action = agent_fn(percept)\n",
    "        world, agent_pos = act(world, agent_pos, action, rows, cols)\n",
    "\n",
    "        score_t = performance_with_energy(world, rows, cols, action)\n",
    "        total_score += score_t\n",
    "\n",
    "        if show:\n",
    "            print(f'Time {t}: action={action}, score_this_step={score_t}')\n",
    "            print_world(world, agent_pos, rows, cols)\n",
    "\n",
    "    return total_score\n",
    "\n",
    "score2 = run_simulation_energy(reflex_agent, steps=8, rows=ROWS, cols=COLS, dirt_prob=0.7, show=True)\n",
    "print('Total score (energy):', score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "1. Did the agent’s behaviour change? Why or why not?\n",
    "2. Is the reflex agent rational under this new performance measure?\n",
    "\n",
    "Write answers below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answers\n",
    "- Q1:\n",
    "- Q2:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Environment Types (Light Practice)\n",
    "\n",
    "AIMA describes environment properties such as:\n",
    "- fully observable vs partially observable\n",
    "- deterministic vs stochastic\n",
    "- episodic vs sequential\n",
    "- static vs dynamic\n",
    "\n",
    "### Task\n",
    "Classify each environment (write short answers):\n",
    "1. This vacuum world\n",
    "2. Chess\n",
    "3. Driving in London\n",
    "4. A recommendation system (Netflix/YouTube)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answers\n",
    "1. Vacuum world:\n",
    "2. Chess:\n",
    "3. Driving in London:\n",
    "4. Recommendation system:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Optional Challenge (For fast finishers)\n",
    "\n",
    "### Challenge A: Better Reflex Agent\n",
    "Change the agent so that when the current square is clean it prefers to move toward a dirty square.\n",
    "\n",
    "Hints:\n",
    "- You will need to give the agent more information (more percepts).\n",
    "- For example, sense *adjacent squares*.\n",
    "\n",
    "### Challenge B: Bigger world\n",
    "Try a 3×3 grid and see how performance changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Exit Ticket (The things we need to know by today)\n",
    "\n",
    "Answer briefly:\n",
    "1. In one sentence, what is an **agent**?\n",
    "2. In one sentence, what does **rational** mean in AI?\n",
    "3. Name one thing that makes real environments harder than this vacuum world.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your exit ticket\n",
    "1.\n",
    "2.\n",
    "3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
