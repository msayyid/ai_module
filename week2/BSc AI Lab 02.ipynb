{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Artificial Intelligence (BSc)\n",
    "## Week 2 — What is AI? What is an Agent? (AIMA Ch. 2)\n",
    "\n",
    "Name: Mukhammadsaiid Norbaev\n",
    "\n",
    "Date of last update: 08/02/2026\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c561335f",
   "metadata": {},
   "source": [
    "### Today’s goals\n",
    "By the end of this notebook you should be able to:\n",
    "- Explain what an **agent** is (in AI terms).\n",
    "- Describe an **environment** and its key properties.\n",
    "- Define **rationality** using performance measures and constraints.\n",
    "- Implement and explain a very simple **reflex agent**.\n",
    "- Practise **explainability**: explain *why* your agent acts the way it does.\n",
    "\n",
    "### How to use this notebook\n",
    "- Read the markdown cells first.\n",
    "- Run code cells in order.\n",
    "- Fill in the **TODO** sections.\n",
    "- Answer the reflection questions in **your own words**.\n",
    "\n",
    "### Reading\n",
    "- Russell & Norvig (AIMA), Chapter 2: Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "Run this cell first. If something errors, ask for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "print('Setup complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Concepts: Agent, Environment, Percepts, Actions\n",
    "\n",
    "In AIMA, an **agent** is anything that:\n",
    "- **perceives** its environment (gets percepts)\n",
    "- **acts** in the environment (takes actions)\n",
    "\n",
    "A simple picture:\n",
    "\n",
    "**Environment → Percepts → Agent → Actions → Environment**\n",
    "\n",
    "### Quick check (write your answers)\n",
    "**Q1:** Is a calculator an agent? Why or why not?\n",
    "\n",
    "**Q2:** Is a thermostat an agent? Why or why not?\n",
    "\n",
    "Write answers below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answers\n",
    "- Q1: yes, it is. as it acts within an environment in case of a caclulator it would be numbers and maths operators. it takes data and processes and gives the result, everything within an environment\n",
    "- Q2: yes, it could also be considered an agent, environment in this case would be the temperature bar, and it takes percepts, which is it checking temperature and it takes action changing the its environment, the temperature bar accordingly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A Tiny Environment: 2×2 Vacuum World\n",
    "\n",
    "We will use a very small **grid environment**:\n",
    "- The agent is on one square.\n",
    "- Each square is either **dirty** or **clean**.\n",
    "- The agent can:\n",
    "  - move up/down/left/right\n",
    "  - clean (\"SUCK\")\n",
    "\n",
    "### Why this environment?\n",
    "It is small enough to understand *every step* and still illustrates real AI ideas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial world:\n",
      "AC .D\n",
      ".D .D\n",
      "\n",
      "{(0, 0): False, (0, 1): True, (1, 0): True, (1, 1): True}\n",
      "Initial world:\n",
      "\n",
      "(0, 0): A  |  CLEAN (False)\n",
      "(0, 1): .  |  DIRTY (True)\n",
      "\n",
      "(1, 0): .  |  DIRTY (True)\n",
      "(1, 1): .  |  DIRTY (True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Environment settings\n",
    "ROWS = 2\n",
    "COLS = 2\n",
    "\n",
    "ACTIONS = ['UP', 'DOWN', 'LEFT', 'RIGHT', 'SUCK']\n",
    "\n",
    "# We represent the world as a dictionary:\n",
    "# world[(r, c)] = True means DIRTY\n",
    "# world[(r, c)] = False means CLEAN\n",
    "\n",
    "def make_random_world(rows: int, cols: int, dirt_prob: float = 0.7) -> Dict[Tuple[int,int], bool]:\n",
    "    # dirt_prob - controls the probability that each cell starts dirty\n",
    "    world = {}\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            world[(r, c)] = (random.random() < dirt_prob)\n",
    "            # random.random() returns a float between 0.0 and 1.0\n",
    "            # and the value will either be True (if float is < 0.7) or False (if float is > 0.7)\n",
    "    return world\n",
    "\n",
    "def print_world(world: Dict[Tuple[int,int], bool], agent_pos: Tuple[int,int], rows: int, cols: int) -> None:\n",
    "    # Simple text display\n",
    "    for r in range(rows):\n",
    "        row_cells = []\n",
    "        for c in range(cols): # column iteration; left to right\n",
    "            is_dirty = world[(r, c)] # boolean, checks whether value at this key is true(dirty) or false(clean)\n",
    "            if (r, c) == agent_pos: # agent position check \n",
    "                cell = 'A'  # agent is here\n",
    "            else:\n",
    "                cell = '.' # if agent is not here\n",
    "            cell += 'D' if is_dirty else 'C' # adding dirt status ex: if A and is_dirty => \"AD\", else \".C\"\n",
    "            row_cells.append(cell) # adds the finished cell string\n",
    "        print(' '.join(row_cells))\n",
    "        # prints one row, space-seperated\n",
    "    print()\n",
    "\n",
    "\n",
    "def print_world_verbose(world, agent_pos, rows, cols):\n",
    "    # print the same thing but different looking\n",
    "    print(\"Initial world:\\n\")\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            is_dirty = world[(r, c)]\n",
    "            agent = \"A\" if (r, c) == agent_pos else \".\"\n",
    "            state = \"DIRTY\" if is_dirty else \"CLEAN\"\n",
    "            print(f\"({r}, {c}): {agent}  |  {state} ({is_dirty})\")\n",
    "        print()\n",
    "\n",
    "world = make_random_world(ROWS, COLS, dirt_prob=0.7)\n",
    "agent_pos = (0, 0)\n",
    "\n",
    "print('Initial world:')\n",
    "print_world(world, agent_pos, ROWS, COLS)\n",
    "\n",
    "print(world)\n",
    "\n",
    "print_world_verbose(world, agent_pos, ROWS, COLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Separating Environment from Agent\n",
    "\n",
    "For explainability, we will separate:\n",
    "- **Sense** (environment → percept)\n",
    "- **Agent** (percept → action)\n",
    "- **Act** (environment + action → new environment)\n",
    "\n",
    "This separation helps you explain:\n",
    "- what the agent knows\n",
    "- what the agent decides\n",
    "- how the environment changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example percept: {'pos': (0, 0), 'is_dirty_here': False}\n"
     ]
    }
   ],
   "source": [
    "def sense(world: Dict[Tuple[int,int], bool], agent_pos: Tuple[int,int]) -> Dict[str, object]:\n",
    "    \"\"\"Return the percept. Here: location and whether current square is dirty.\"\"\"\n",
    "    # the point here is separation of concerns, core ai concept\n",
    "    # agent receives only where it is and whether its current tile is dirty, not the full world\n",
    "    \"\"\"in ai, an agent:\n",
    "    does not have access to world\n",
    "    only receives a percept from the environment\n",
    "    this function simulates that boundary\n",
    "    sense() is like the contract that limits what the agent is allowed to know about the world.\"\"\"\n",
    "    r, c = agent_pos\n",
    "    percept = {\n",
    "        'pos': agent_pos,\n",
    "        'is_dirty_here': world[(r, c)]\n",
    "    }\n",
    "    return percept\n",
    "\n",
    "def act(world: Dict[Tuple[int,int], bool], agent_pos: Tuple[int,int], action: str, rows: int, cols: int) -> Tuple[Dict[Tuple[int,int], bool], Tuple[int,int]]:\n",
    "    \"\"\"Apply the action to the environment. Returns (new_world, new_agent_pos).\"\"\"\n",
    "    r, c = agent_pos\n",
    "    new_world = dict(world)  # copy\n",
    "    new_pos = agent_pos\n",
    "\n",
    "    if action == 'SUCK':\n",
    "        # Clean the current square\n",
    "        new_world[(r, c)] = False # false means clean\n",
    "        return new_world, new_pos # changed world is returned, given tile has been cleaned\n",
    "\n",
    "    if action == 'UP':\n",
    "        if r > 0: # this checks whether it is possible to go up\n",
    "            new_pos = (r - 1, c)\n",
    "    elif action == 'DOWN':\n",
    "        if r < rows - 1:\n",
    "            new_pos = (r + 1, c)\n",
    "    elif action == 'LEFT':\n",
    "        if c > 0:\n",
    "            new_pos = (r, c - 1)\n",
    "    elif action == 'RIGHT':\n",
    "        if c < cols - 1:\n",
    "            new_pos = (r, c + 1)\n",
    "\n",
    "    return new_world, new_pos\n",
    "\n",
    "percept = sense(world, agent_pos)\n",
    "print('Example percept:', percept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. A Simple Reflex Agent\n",
    "\n",
    "A reflex agent uses **if–else rules**.\n",
    "\n",
    "### Reflex rule (very simple)\n",
    "- If current square is dirty → SUCK\n",
    "- Otherwise → move randomly\n",
    "\n",
    "This is not “smart”, but it is a valid agent.\n",
    "\n",
    "### TODO\n",
    "Read the function and make sure you can explain it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If dirty -> SUCK\n",
      "If clean -> LEFT\n"
     ]
    }
   ],
   "source": [
    "def reflex_agent(percept: Dict[str, object]) -> str:\n",
    "    # percept: Dict[str, object] -- this is a type contract that says:\n",
    "    # keys must be str\n",
    "    # values must be instances of object\n",
    "    \"\"\"the reflex agent does not care about pos, types; it only cares that \" is_dirty_here\" exists, it is true or false\"\"\"\n",
    "    if percept['is_dirty_here']:\n",
    "        return 'SUCK'\n",
    "    else:\n",
    "        return random.choice(['UP', 'DOWN', 'LEFT', 'RIGHT'])\n",
    "\n",
    "# Test the agent decision once\n",
    "test_percept = {'pos': (0,0), 'is_dirty_here': True}\n",
    "print('If dirty ->', reflex_agent(test_percept))\n",
    "test_percept = {'pos': (0,0), 'is_dirty_here': False}\n",
    "print('If clean ->', reflex_agent(test_percept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Running a Simulation\n",
    "\n",
    "We will run the agent for a number of steps.\n",
    "\n",
    "### Performance measure\n",
    "We need a way to say if the agent is doing well.\n",
    "\n",
    "For now:\n",
    "- **+1** point for each clean square at each time step\n",
    "\n",
    "This means the agent is rewarded for keeping the world clean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(world: Dict[Tuple[int,int], bool], rows: int, cols: int) -> int:\n",
    "    # Count clean squares\n",
    "    clean = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if world[(r, c)] == False:\n",
    "                clean += 1\n",
    "    return clean\n",
    "\n",
    "def run_simulation(agent_fn, steps: int = 10, rows: int = 2, cols: int = 2, dirt_prob: float = 0.7, show: bool = True):\n",
    "    world = make_random_world(rows, cols, dirt_prob)\n",
    "    agent_pos = (0, 0)\n",
    "    total_score = 0\n",
    "\n",
    "    if show:\n",
    "        print('Starting simulation...')\n",
    "        print_world(world, agent_pos, rows, cols)\n",
    "\n",
    "    for t in range(steps):\n",
    "        percept = sense(world, agent_pos)\n",
    "        action = agent_fn(percept)\n",
    "        world, agent_pos = act(world, agent_pos, action, rows, cols)\n",
    "\n",
    "        score_t = performance(world, rows, cols)\n",
    "        total_score += score_t\n",
    "\n",
    "        if show:\n",
    "            print(f'Time {t}: action={action}, score_this_step={score_t}')\n",
    "            print_world(world, agent_pos, rows, cols)\n",
    "\n",
    "    return total_score\n",
    "\n",
    "score = run_simulation(reflex_agent, steps=8, rows=ROWS, cols=COLS, dirt_prob=0.7, show=True)\n",
    "print('Total score:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Explainability Task (Important)\n",
    "\n",
    "Answer in your own words:\n",
    "\n",
    "1. What information does the agent use to decide?\n",
    "2. Why does the agent sometimes move \"badly\"?\n",
    "3. What is the agent trying to maximise in this environment?\n",
    "\n",
    "Write answers below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answers\n",
    "- Q1:\n",
    "- Q2:\n",
    "- Q3:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Rationality Depends on the Performance Measure\n",
    "\n",
    "Let’s change what we mean by “good”.\n",
    "\n",
    "### New performance measure\n",
    "- Clean squares are good\n",
    "- BUT moving costs energy\n",
    "\n",
    "We will implement:\n",
    "- +1 for each clean square per step\n",
    "- -1 for every move action\n",
    "\n",
    "### TODO\n",
    "Complete the function `performance_with_energy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_with_energy(world: Dict[Tuple[int,int], bool], rows: int, cols: int, last_action: str) -> int:\n",
    "    # TODO: start from clean squares score\n",
    "    clean_score = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if world[(r, c)] == False:\n",
    "                clean_score += 1\n",
    "\n",
    "    # TODO: subtract 1 for move actions (UP/DOWN/LEFT/RIGHT)\n",
    "    move_penalty = 0\n",
    "    if last_action in ['UP', 'DOWN', 'LEFT', 'RIGHT']:\n",
    "        move_penalty = 1\n",
    "\n",
    "    return clean_score - move_penalty\n",
    "\n",
    "def run_simulation_energy(agent_fn, steps: int = 10, rows: int = 2, cols: int = 2, dirt_prob: float = 0.7, show: bool = True):\n",
    "    world = make_random_world(rows, cols, dirt_prob)\n",
    "    agent_pos = (0, 0)\n",
    "    total_score = 0\n",
    "\n",
    "    if show:\n",
    "        print('Starting simulation (energy cost)...')\n",
    "        print_world(world, agent_pos, rows, cols)\n",
    "\n",
    "    for t in range(steps):\n",
    "        percept = sense(world, agent_pos)\n",
    "        action = agent_fn(percept)\n",
    "        world, agent_pos = act(world, agent_pos, action, rows, cols)\n",
    "\n",
    "        score_t = performance_with_energy(world, rows, cols, action)\n",
    "        total_score += score_t\n",
    "\n",
    "        if show:\n",
    "            print(f'Time {t}: action={action}, score_this_step={score_t}')\n",
    "            print_world(world, agent_pos, rows, cols)\n",
    "\n",
    "    return total_score\n",
    "\n",
    "score2 = run_simulation_energy(reflex_agent, steps=8, rows=ROWS, cols=COLS, dirt_prob=0.7, show=True)\n",
    "print('Total score (energy):', score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "1. Did the agent’s behaviour change? Why or why not?\n",
    "2. Is the reflex agent rational under this new performance measure?\n",
    "\n",
    "Write answers below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answers\n",
    "- Q1:\n",
    "- Q2:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Environment Types (Light Practice)\n",
    "\n",
    "AIMA describes environment properties such as:\n",
    "- fully observable vs partially observable\n",
    "- deterministic vs stochastic\n",
    "- episodic vs sequential\n",
    "- static vs dynamic\n",
    "\n",
    "### Task\n",
    "Classify each environment (write short answers):\n",
    "1. This vacuum world\n",
    "2. Chess\n",
    "3. Driving in London\n",
    "4. A recommendation system (Netflix/YouTube)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answers\n",
    "1. Vacuum world:\n",
    "2. Chess:\n",
    "3. Driving in London:\n",
    "4. Recommendation system:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Optional Challenge (For fast finishers)\n",
    "\n",
    "### Challenge A: Better Reflex Agent\n",
    "Change the agent so that when the current square is clean it prefers to move toward a dirty square.\n",
    "\n",
    "Hints:\n",
    "- You will need to give the agent more information (more percepts).\n",
    "- For example, sense *adjacent squares*.\n",
    "\n",
    "### Challenge B: Bigger world\n",
    "Try a 3×3 grid and see how performance changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Exit Ticket (The things we need to know by today)\n",
    "\n",
    "Answer briefly:\n",
    "1. In one sentence, what is an **agent**?\n",
    "2. In one sentence, what does **rational** mean in AI?\n",
    "3. Name one thing that makes real environments harder than this vacuum world.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your exit ticket\n",
    "1.\n",
    "2.\n",
    "3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
